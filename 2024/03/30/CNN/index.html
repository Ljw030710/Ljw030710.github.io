<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>CNN | Hexo</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、常用的方向：人脸识别（主要是特征值的提取），检测任务，分类和检索，超分辨率重构（用于图片），医学任务，一些识别，无人驾驶。 二、与传统神经网络的区别：【科普贴】从神经网络到卷积神经网络 - 知乎 (zhihu.com)卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28*28*1就是变成个三维，也许可以减小数据">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN">
<meta property="og:url" content="http://example.com/2024/03/30/CNN/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、常用的方向：人脸识别（主要是特征值的提取），检测任务，分类和检索，超分辨率重构（用于图片），医学任务，一些识别，无人驾驶。 二、与传统神经网络的区别：【科普贴】从神经网络到卷积神经网络 - 知乎 (zhihu.com)卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28*28*1就是变成个三维，也许可以减小数据">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-03-30T09:04:42.000Z">
<meta property="article:modified_time" content="2024-03-30T09:12:49.371Z">
<meta property="article:author" content="iolzyy">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>

  
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
				<img lazy-src="https://download.tooc.xlj0.com/uploads/179/leimu.jpg" class="js-avatar">
			
		</a>

		<hgroup>
			<h1 class="header-author"><a href="/">iolzyy</a></h1>
		</hgroup>

		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Archives</a></li>
				        
						</ul>
					</nav>
					<nav class="half-header-menu">
						<a class="hide">Home</a>
						<a>Tags</a>
						<a>Links</a>
						<a>About</a>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
						<!-- music -->
						
							<!-- <div style="position: absolute; bottom: 120px; left: auto; width: 85%;"> -->
							<div style="position: absolute; left: auto; width: 85%;">
								<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=220 height=86 src="//music.163.com/outchain/player?type=2&id=id=https://music.163.com/song?id=1944058085&userid=1954034794&auto=1&height=66"></iframe>
							</div>
						
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Atcoder/" style="font-size: 10px;">Atcoder</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 17.5px;">前端</a> <a href="/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/" style="font-size: 12.5px;">前端学习</a> <a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 10px;">博客</a> <a href="/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">博客搭建</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/" style="font-size: 20px;">基础算法</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 12.5px;">深度学习</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/" style="font-size: 12.5px;">算法基础</a> <a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 15px;">蓝桥杯</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/">github</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://blog.tiancy.top/">tiancy</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://blog.cnpatrickstar.com/">派大星</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://salt114514.github.io/">salt</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="/blog.bluebird.icu">青鸟</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://houbb.github.io/">echo</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">I&#39;m a developer.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://download.tooc.xlj0.com/uploads/179/leimu.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author"></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Archives</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-CNN" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2024/03/30/CNN/" class="article-date">
  	<time datetime="2024-03-30T09:04:42.000Z" itemprop="datePublished">2024-03-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CNN
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
	</div>

        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、常用的方向：人脸识别（主要是特征值的提取），检测任务，分类和检索，超分辨率重构（用于图片），医学任务，一些识别，无人驾驶。</p>
<h3 id="二、与传统神经网络的区别：【科普贴】从神经网络到卷积神经网络-知乎-zhihu-com-卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28-28-1就是变成个三维，也许可以减小数据量，或者是为了卷积层更好的提取特征。"><a href="#二、与传统神经网络的区别：【科普贴】从神经网络到卷积神经网络-知乎-zhihu-com-卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28-28-1就是变成个三维，也许可以减小数据量，或者是为了卷积层更好的提取特征。" class="headerlink" title="二、与传统神经网络的区别：【科普贴】从神经网络到卷积神经网络 - 知乎 (zhihu.com)卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28*28*1就是变成个三维，也许可以减小数据量，或者是为了卷积层更好的提取特征。"></a>二、与传统神经网络的区别：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/242853150">【科普贴】从神经网络到卷积神经网络 - 知乎 (zhihu.com)</a>卷积神经网络是会比传统的神经网络有更高的维度，神经网络是nn，卷积是cnn，就比如说传统的神经网络是784个像素点，而卷积神经是分成28<code>*</code>28<code>*</code>1就是变成个三维，也许可以减小数据量，或者是为了卷积层更好的提取特征。</h3><h3 id="三、整体架构：分为输入层，卷积层，池化层，全连接层。"><a href="#三、整体架构：分为输入层，卷积层，池化层，全连接层。" class="headerlink" title="三、整体架构：分为输入层，卷积层，池化层，全连接层。"></a>三、整体架构：分为输入层，卷积层，池化层，全连接层。</h3><h4 id="输入层：输入数据；"><a href="#输入层：输入数据；" class="headerlink" title="输入层：输入数据；"></a>输入层：输入数据；</h4><h4 id="卷积层：使用卷积核进行特征提取和特征映射。"><a href="#卷积层：使用卷积核进行特征提取和特征映射。" class="headerlink" title="卷积层：使用卷积核进行特征提取和特征映射。"></a>卷积层：使用卷积核进行特征提取和特征映射。</h4><h4 id="池化层：进行采样降维。"><a href="#池化层：进行采样降维。" class="headerlink" title="池化层：进行采样降维。"></a>池化层：进行采样降维。</h4><h4 id="全连接层：在尾部进行拟合，减少特征信息的损失。"><a href="#全连接层：在尾部进行拟合，减少特征信息的损失。" class="headerlink" title="全连接层：在尾部进行拟合，减少特征信息的损失。"></a>全连接层：在尾部进行拟合，减少特征信息的损失。</h4><h3 id="四，卷积做了什么；"><a href="#四，卷积做了什么；" class="headerlink" title="四，卷积做了什么；"></a>四，卷积做了什么；</h3><p>![[Pasted image 20240325203433.png]]</p>
<h4 id="从就是kernel就是一个卷积核，通过卷积核，然后放入的案例划分的图形划分的小区域也应该是和卷积核一样。最后计算出来特征图。"><a href="#从就是kernel就是一个卷积核，通过卷积核，然后放入的案例划分的图形划分的小区域也应该是和卷积核一样。最后计算出来特征图。" class="headerlink" title="从就是kernel就是一个卷积核，通过卷积核，然后放入的案例划分的图形划分的小区域也应该是和卷积核一样。最后计算出来特征图。"></a>从就是kernel就是一个卷积核，通过卷积核，然后放入的案例划分的图形划分的小区域也应该是和卷积核一样。最后计算出来特征图。</h4><h4 id="五、卷积特征值的计算方法"><a href="#五、卷积特征值的计算方法" class="headerlink" title="五、卷积特征值的计算方法"></a>五、卷积特征值的计算方法</h4><h4 id="首先是颜色通道是分为RGB，然后一个特征值的计算是需要RGB三个通道和卷积核计算得到。-Pasted-image-20240325205403-png"><a href="#首先是颜色通道是分为RGB，然后一个特征值的计算是需要RGB三个通道和卷积核计算得到。-Pasted-image-20240325205403-png" class="headerlink" title="首先是颜色通道是分为RGB，然后一个特征值的计算是需要RGB三个通道和卷积核计算得到。![[Pasted image 20240325205403.png]]"></a>首先是颜色通道是分为RGB，然后一个特征值的计算是需要RGB三个通道和卷积核计算得到。![[Pasted image 20240325205403.png]]</h4><h4 id="我们可以把左边蓝色的三个分别视为RGB三个颜色通道，然后他们的卷积核各不同因为像素点是不同的，还有就是蓝色部分是773，然后w是333，第三个数值两个需要对应上，就是都必须是一样的。然后计算方法就是-直接×，就比如第一个就是0，因为1-1加1×1-0，其他都是0。然后三个计算出来是2，我们可以看到最下面是有个bias偏移值是1，所以我们加上偏移值就是3。"><a href="#我们可以把左边蓝色的三个分别视为RGB三个颜色通道，然后他们的卷积核各不同因为像素点是不同的，还有就是蓝色部分是773，然后w是333，第三个数值两个需要对应上，就是都必须是一样的。然后计算方法就是-直接×，就比如第一个就是0，因为1-1加1×1-0，其他都是0。然后三个计算出来是2，我们可以看到最下面是有个bias偏移值是1，所以我们加上偏移值就是3。" class="headerlink" title="我们可以把左边蓝色的三个分别视为RGB三个颜色通道，然后他们的卷积核各不同因为像素点是不同的，还有就是蓝色部分是773，然后w是333，第三个数值两个需要对应上，就是都必须是一样的。然后计算方法就是 直接×，就比如第一个就是0，因为1*-1加1×1&#x3D;0，其他都是0。然后三个计算出来是2，我们可以看到最下面是有个bias偏移值是1，所以我们加上偏移值就是3。"></a>我们可以把左边蓝色的三个分别视为RGB三个颜色通道，然后他们的卷积核各不同因为像素点是不同的，还有就是蓝色部分是773，然后w是333，第三个数值两个需要对应上，就是都必须是一样的。然后计算方法就是 直接×，就比如第一个就是0，因为1*-1加1×1&#x3D;0，其他都是0。然后三个计算出来是2，我们可以看到最下面是有个bias偏移值是1，所以我们加上偏移值就是3。</h4><h3 id="六，得到特征图表示"><a href="#六，得到特征图表示" class="headerlink" title="六，得到特征图表示"></a>六，得到特征图表示</h3><h4 id="其实我们看上图，是有两种卷积核，w0和w1，所以我们可以看到可以得到两张特征图，所以如果卷积核的种类不同的话，那么就是特征图就会越来越多，那么特征会越来越丰富。"><a href="#其实我们看上图，是有两种卷积核，w0和w1，所以我们可以看到可以得到两张特征图，所以如果卷积核的种类不同的话，那么就是特征图就会越来越多，那么特征会越来越丰富。" class="headerlink" title="其实我们看上图，是有两种卷积核，w0和w1，所以我们可以看到可以得到两张特征图，所以如果卷积核的种类不同的话，那么就是特征图就会越来越多，那么特征会越来越丰富。"></a>其实我们看上图，是有两种卷积核，w0和w1，所以我们可以看到可以得到两张特征图，所以如果卷积核的种类不同的话，那么就是特征图就会越来越多，那么特征会越来越丰富。</h4><h3 id="七，步长与卷积核大小对结果的影响。"><a href="#七，步长与卷积核大小对结果的影响。" class="headerlink" title="七，步长与卷积核大小对结果的影响。"></a>七，步长与卷积核大小对结果的影响。</h3><h4 id="对特征图基础上行多次卷积。"><a href="#对特征图基础上行多次卷积。" class="headerlink" title="对特征图基础上行多次卷积。"></a>对特征图基础上行多次卷积。</h4><p>![[Pasted image 20240325233943.png]]<br>![[Pasted image 20240325234007.png]]</p>
<h5 id="我们可以看到第一个红色的c是3，三代表有多少个特征图。就是接下来的卷积核的c就是前面对应的，如果就是然后就会有蓝色，就是六个特征图。eg10表示用十个不同的filter来执行卷积。"><a href="#我们可以看到第一个红色的c是3，三代表有多少个特征图。就是接下来的卷积核的c就是前面对应的，如果就是然后就会有蓝色，就是六个特征图。eg10表示用十个不同的filter来执行卷积。" class="headerlink" title="我们可以看到第一个红色的c是3，三代表有多少个特征图。就是接下来的卷积核的c就是前面对应的，如果就是然后就会有蓝色，就是六个特征图。eg10表示用十个不同的filter来执行卷积。"></a>我们可以看到第一个红色的c是3，三代表有多少个特征图。就是接下来的卷积核的c就是前面对应的，如果就是然后就会有蓝色，就是六个特征图。eg10表示用十个不同的filter来执行卷积。</h5><h4 id="滑动窗口步长"><a href="#滑动窗口步长" class="headerlink" title="滑动窗口步长"></a>滑动窗口步长</h4><p>![[Pasted image 20240325235101.png]]</p>
<h5 id="对于步长为1就是特征值会更加丰富，步长为2他的特征值会比较粗糙，但是速度会快点，步长不不一样会用到特定的场景。"><a href="#对于步长为1就是特征值会更加丰富，步长为2他的特征值会比较粗糙，但是速度会快点，步长不不一样会用到特定的场景。" class="headerlink" title="对于步长为1就是特征值会更加丰富，步长为2他的特征值会比较粗糙，但是速度会快点，步长不不一样会用到特定的场景。"></a>对于步长为1就是特征值会更加丰富，步长为2他的特征值会比较粗糙，但是速度会快点，步长不不一样会用到特定的场景。</h5><h4 id="卷积核的尺寸"><a href="#卷积核的尺寸" class="headerlink" title="卷积核的尺寸"></a>卷积核的尺寸</h4><h5 id="取决于进行对于目标图像的划分，就比如上图是3×3，所以它的卷积核尺寸是3×3。"><a href="#取决于进行对于目标图像的划分，就比如上图是3×3，所以它的卷积核尺寸是3×3。" class="headerlink" title="取决于进行对于目标图像的划分，就比如上图是3×3，所以它的卷积核尺寸是3×3。"></a>取决于进行对于目标图像的划分，就比如上图是3×3，所以它的卷积核尺寸是3×3。</h5><h4 id="边缘填充方法"><a href="#边缘填充方法" class="headerlink" title="边缘填充方法"></a>边缘填充方法</h4><p>![[Pasted image 20240326104300.png]]</p>
<h5 id="我们可以看到左边的三张图，就是紫色的区域才是真正的样本值，然后我们在计算的时候会发现如果没有边界填充，一些数字会对特征图的结果有比较大的影响，而且边界值和中心值的重要程度就会出现区别，而边界填充的目的是能更公平的对待边界值和中心值。为什么图中只是加了一圈，因为上方有个pad-1。"><a href="#我们可以看到左边的三张图，就是紫色的区域才是真正的样本值，然后我们在计算的时候会发现如果没有边界填充，一些数字会对特征图的结果有比较大的影响，而且边界值和中心值的重要程度就会出现区别，而边界填充的目的是能更公平的对待边界值和中心值。为什么图中只是加了一圈，因为上方有个pad-1。" class="headerlink" title="我们可以看到左边的三张图，就是紫色的区域才是真正的样本值，然后我们在计算的时候会发现如果没有边界填充，一些数字会对特征图的结果有比较大的影响，而且边界值和中心值的重要程度就会出现区别，而边界填充的目的是能更公平的对待边界值和中心值。为什么图中只是加了一圈，因为上方有个pad &#x3D; 1。"></a>我们可以看到左边的三张图，就是紫色的区域才是真正的样本值，然后我们在计算的时候会发现如果没有边界填充，一些数字会对特征图的结果有比较大的影响，而且边界值和中心值的重要程度就会出现区别，而边界填充的目的是能更公平的对待边界值和中心值。为什么图中只是加了一圈，因为上方有个pad &#x3D; 1。</h5><h4 id="卷积核个数"><a href="#卷积核个数" class="headerlink" title="卷积核个数"></a>卷积核个数</h4><h5 id="就是多少个特征图，就要多少个卷积核。"><a href="#就是多少个特征图，就要多少个卷积核。" class="headerlink" title="就是多少个特征图，就要多少个卷积核。"></a>就是多少个特征图，就要多少个卷积核。</h5><h3 id="八，特征图尺寸计算和参数共享"><a href="#八，特征图尺寸计算和参数共享" class="headerlink" title="八，特征图尺寸计算和参数共享"></a>八，特征图尺寸计算和参数共享</h3><h4 id="卷积结果计算公式"><a href="#卷积结果计算公式" class="headerlink" title="卷积结果计算公式"></a>卷积结果计算公式</h4><p>![[Pasted image 20240326163117.png]]</p>
<h4 id="为什么是加2p因为一圈，左右两边都会加，所以是加2p。"><a href="#为什么是加2p因为一圈，左右两边都会加，所以是加2p。" class="headerlink" title="为什么是加2p因为一圈，左右两边都会加，所以是加2p。"></a>为什么是加2p因为一圈，左右两边都会加，所以是加2p。</h4><p>![[Pasted image 20240326163842.png]]</p>
<h4 id="通过这张图可以看出怎么计算。"><a href="#通过这张图可以看出怎么计算。" class="headerlink" title="通过这张图可以看出怎么计算。"></a>通过这张图可以看出怎么计算。</h4><h4 id="卷积参数共享"><a href="#卷积参数共享" class="headerlink" title="卷积参数共享"></a>卷积参数共享</h4><p>![[Pasted image 20240326165236.png]]</p>
<h5 id="就是一个filter可以出一张特征图，然后计算参数就是把一个卷积核按照hwc给算出来，然后加上对应的偏执参数就算出来一个卷积核的权重参数。"><a href="#就是一个filter可以出一张特征图，然后计算参数就是把一个卷积核按照hwc给算出来，然后加上对应的偏执参数就算出来一个卷积核的权重参数。" class="headerlink" title="就是一个filter可以出一张特征图，然后计算参数就是把一个卷积核按照hwc给算出来，然后加上对应的偏执参数就算出来一个卷积核的权重参数。"></a>就是一个filter可以出一张特征图，然后计算参数就是把一个卷积核按照hwc给算出来，然后加上对应的偏执参数就算出来一个卷积核的权重参数。</h5><h3 id="九，池化层的作用"><a href="#九，池化层的作用" class="headerlink" title="九，池化层的作用"></a>九，池化层的作用</h3><p>![[Pasted image 20240327204655.png]]</p>
<h4 id="可以看到和卷积层的划分是类似的，化成一块一块的，然后找到里面最大，就是特征值最大的，然后拼成一块，这种操作是最大池化。池化层的作用也可以看出来，就是减小规模。"><a href="#可以看到和卷积层的划分是类似的，化成一块一块的，然后找到里面最大，就是特征值最大的，然后拼成一块，这种操作是最大池化。池化层的作用也可以看出来，就是减小规模。" class="headerlink" title="可以看到和卷积层的划分是类似的，化成一块一块的，然后找到里面最大，就是特征值最大的，然后拼成一块，这种操作是最大池化。池化层的作用也可以看出来，就是减小规模。"></a>可以看到和卷积层的划分是类似的，化成一块一块的，然后找到里面最大，就是特征值最大的，然后拼成一块，这种操作是最大池化。池化层的作用也可以看出来，就是减小规模。</h4><p>![[Pasted image 20240327205050.png]]</p>
<h3 id="十、整体网络结构"><a href="#十、整体网络结构" class="headerlink" title="十、整体网络结构"></a>十、整体网络结构</h3><p>![[Pasted image 20240327233452.png]]</p>
<h4 id="我们从这张图中可以看出这是几层的神经网络，就是会有权重和参数的层数总和。"><a href="#我们从这张图中可以看出这是几层的神经网络，就是会有权重和参数的层数总和。" class="headerlink" title="我们从这张图中可以看出这是几层的神经网络，就是会有权重和参数的层数总和。"></a>我们从这张图中可以看出这是几层的神经网络，就是会有权重和参数的层数总和。</h4><h4 id="RELU层只是保留特征大于0的值，conv是一个，最后的FC，就是划分也是一层，那么图中就是七层。然后再FC前面还有一步就是将一个立体的几×几×几的把他变成转化成一个就像图中的写的-10240-5"><a href="#RELU层只是保留特征大于0的值，conv是一个，最后的FC，就是划分也是一层，那么图中就是七层。然后再FC前面还有一步就是将一个立体的几×几×几的把他变成转化成一个就像图中的写的-10240-5" class="headerlink" title="RELU层只是保留特征大于0的值，conv是一个，最后的FC，就是划分也是一层，那么图中就是七层。然后再FC前面还有一步就是将一个立体的几×几×几的把他变成转化成一个就像图中的写的[10240,5]"></a>RELU层只是保留特征大于0的值，conv是一个，最后的FC，就是划分也是一层，那么图中就是七层。然后再FC前面还有一步就是将一个立体的几×几×几的把他变成转化成一个就像图中的写的<code>[10240,5]</code></h4><p>![[Pasted image 20240327235319.png]]</p>
<h4 id="特征图变化没什么好说的。转换就是将一个立体转化成一个向量，可以被读进去。"><a href="#特征图变化没什么好说的。转换就是将一个立体转化成一个向量，可以被读进去。" class="headerlink" title="特征图变化没什么好说的。转换就是将一个立体转化成一个向量，可以被读进去。"></a>特征图变化没什么好说的。转换就是将一个立体转化成一个向量，可以被读进去。</h4><h3 id="十一，VGN网络架构"><a href="#十一，VGN网络架构" class="headerlink" title="十一，VGN网络架构"></a>十一，VGN网络架构</h3><h4 id="Alexnet这个比较早就没什么好说的。"><a href="#Alexnet这个比较早就没什么好说的。" class="headerlink" title="Alexnet这个比较早就没什么好说的。"></a>Alexnet这个比较早就没什么好说的。</h4><h4 id="Vgg经典网络"><a href="#Vgg经典网络" class="headerlink" title="Vgg经典网络"></a>Vgg经典网络</h4><p>![[Pasted image 20240330143149.png]]</p>
<h5 id="从这个d来讲这是十六层的神经网络，然后这是十六层的，然后他的划分都是三×三，然后我们发现再经过池化层，本来应该会减少那些没有太大用处的特征值，应该会减少，但是却翻了两倍，说明再池化层之后给了一些数值，弥补一部分损失。"><a href="#从这个d来讲这是十六层的神经网络，然后这是十六层的，然后他的划分都是三×三，然后我们发现再经过池化层，本来应该会减少那些没有太大用处的特征值，应该会减少，但是却翻了两倍，说明再池化层之后给了一些数值，弥补一部分损失。" class="headerlink" title="从这个d来讲这是十六层的神经网络，然后这是十六层的，然后他的划分都是三×三，然后我们发现再经过池化层，本来应该会减少那些没有太大用处的特征值，应该会减少，但是却翻了两倍，说明再池化层之后给了一些数值，弥补一部分损失。"></a>从这个d来讲这是十六层的神经网络，然后这是十六层的，然后他的划分都是三×三，然后我们发现再经过池化层，本来应该会减少那些没有太大用处的特征值，应该会减少，但是却翻了两倍，说明再池化层之后给了一些数值，弥补一部分损失。</h5><h4 id="然后关于如果神经层数太多，有可能会导致loss值过高，或者对应的卷积层做的不是很好，反而会取得适得其反的效果。"><a href="#然后关于如果神经层数太多，有可能会导致loss值过高，或者对应的卷积层做的不是很好，反而会取得适得其反的效果。" class="headerlink" title="然后关于如果神经层数太多，有可能会导致loss值过高，或者对应的卷积层做的不是很好，反而会取得适得其反的效果。"></a>然后关于如果神经层数太多，有可能会导致loss值过高，或者对应的卷积层做的不是很好，反而会取得适得其反的效果。</h4><h3 id="十二、残差网络Resnet"><a href="#十二、残差网络Resnet" class="headerlink" title="十二、残差网络Resnet"></a>十二、残差网络Resnet</h3><h4 id="深层神经网络所遇到的问题：就是train-error值会更高，所以就是需要降低。"><a href="#深层神经网络所遇到的问题：就是train-error值会更高，所以就是需要降低。" class="headerlink" title="深层神经网络所遇到的问题：就是train error值会更高，所以就是需要降低。"></a>深层神经网络所遇到的问题：就是train error值会更高，所以就是需要降低。</h4><h4 id="解决方案：加了Resnet"><a href="#解决方案：加了Resnet" class="headerlink" title="解决方案：加了Resnet"></a>解决方案：加了Resnet</h4><p>![[Pasted image 20240330145212.png]]</p>
<h5 id="这张图的意思是，x相当于input，然后如果有值怎么拟合都拟合不好，那么就会将他的赋值成0，然后会有一个补偿机制，就是加上原来的值，这样的操作使得深层的神经网络的error降低。中间的两层的为卷积层。"><a href="#这张图的意思是，x相当于input，然后如果有值怎么拟合都拟合不好，那么就会将他的赋值成0，然后会有一个补偿机制，就是加上原来的值，这样的操作使得深层的神经网络的error降低。中间的两层的为卷积层。" class="headerlink" title="这张图的意思是，x相当于input，然后如果有值怎么拟合都拟合不好，那么就会将他的赋值成0，然后会有一个补偿机制，就是加上原来的值，这样的操作使得深层的神经网络的error降低。中间的两层的为卷积层。"></a>这张图的意思是，x相当于input，然后如果有值怎么拟合都拟合不好，那么就会将他的赋值成0，然后会有一个补偿机制，就是加上原来的值，这样的操作使得深层的神经网络的error降低。中间的两层的为卷积层。</h5><p>![[Pasted image 20240330145724.png]]</p>
<h4 id="深层的神经网络就会变成这样。"><a href="#深层的神经网络就会变成这样。" class="headerlink" title="深层的神经网络就会变成这样。"></a>深层的神经网络就会变成这样。</h4><h3 id="十三、感受野"><a href="#十三、感受野" class="headerlink" title="十三、感受野"></a>十三、感受野</h3><h4 id="一开始看感觉要一会，但是理解了。"><a href="#一开始看感觉要一会，但是理解了。" class="headerlink" title="一开始看感觉要一会，但是理解了。"></a>一开始看感觉要一会，但是理解了。</h4><h4 id="神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着它可能蕴含更为全局，语义层次更高的特征；相反，值越小则表示其所包含的特征越趋向局部和细节。因此感受野的值可以用来大致判断每一层的抽象层次"><a href="#神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着它可能蕴含更为全局，语义层次更高的特征；相反，值越小则表示其所包含的特征越趋向局部和细节。因此感受野的值可以用来大致判断每一层的抽象层次" class="headerlink" title="神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着它可能蕴含更为全局，语义层次更高的特征；相反，值越小则表示其所包含的特征越趋向局部和细节。因此感受野的值可以用来大致判断每一层的抽象层次."></a>神经元感受野的值越大表示其能接触到的原始图像范围就越大，也意味着它可能蕴含更为全局，语义层次更高的特征；相反，值越小则表示其所包含的特征越趋向局部和细节。因此<strong>感受野的值可以用来大致判断每一层的抽象层次</strong>.</h4><h4 id="如何算感受野"><a href="#如何算感受野" class="headerlink" title="如何算感受野"></a>如何算感受野</h4><h5 id="例子：求三个3×3的卷积层，保持步长为一，求它的感受野。"><a href="#例子：求三个3×3的卷积层，保持步长为一，求它的感受野。" class="headerlink" title="例子：求三个3×3的卷积层，保持步长为一，求它的感受野。"></a>例子：求三个3×3的卷积层，保持步长为一，求它的感受野。</h5><h4 id="公式：前一层卷积核感受野-（后一层卷积核感受野-1）x-前一层卷积核步长-前一层卷积核的大小"><a href="#公式：前一层卷积核感受野-（后一层卷积核感受野-1）x-前一层卷积核步长-前一层卷积核的大小" class="headerlink" title="公式：前一层卷积核感受野 &#x3D; （后一层卷积核感受野 - 1）x 前一层卷积核步长 + 前一层卷积核的大小"></a>公式：<strong>前一层卷积核感受野 &#x3D; （后一层卷积核感受野 - 1）x 前一层卷积核步长 + 前一层卷积核的大小</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">首先是最后一层是一个，(1-1)*1+3 = 3</span><br><span class="line">接着计算：(3-1)*1+3 = 5</span><br><span class="line">然后计算:(5-1)*1+3 = 7</span><br><span class="line">所以感受野即为7</span><br></pre></td></tr></table></figure>
<h4 id="问题：为什么要堆叠三个小卷积："><a href="#问题：为什么要堆叠三个小卷积：" class="headerlink" title="问题：为什么要堆叠三个小卷积："></a>问题：为什么要堆叠三个小卷积：</h4>
      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/04/16/GNN/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          GNN
        
      </div>
    </a>
  
  
    <a href="/2024/03/02/%E4%BA%8C%E5%88%86%E9%A2%98%E5%8D%95/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">二分题单</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>






</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2024 iolzyy
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/preccrep/hexo-theme-jelly" target="_blank">Jelly</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">



<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: false,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>

<script src="/js/main.js"></script>




  </div>
</body>
</html>